#!/usr/bin/env python3
"""
–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–∏–º–µ—Ä –≤–µ–±-—Å–∫—Ä–∞–ø–µ—Ä–∞ OpenReview —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ä–µ–≤—å—é

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:
- –°–∫—Ä–∞–ø–∏–Ω–≥ —Å—Ç–∞—Ç–µ–π —Å OpenReview
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–≤—å—é
- –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏
"""

from scraper import Scraper
from extract import Extractor
from filters import title_filter, keywords_filter, abstract_filter, reviews_filter
from selector import Selector
from utils import save_papers, load_papers

def main():
    print("üöÄ OPENREVIEW SCRAPER –° –ò–ó–í–õ–ï–ß–ï–ù–ò–ï–ú –†–ï–í–¨–Æ")
    print("=" * 50)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞
    years = ['2024']
    conferences = ['ICLR']
    keywords = [
        'language',     # –æ–±—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–π–¥—É—Ç –±–æ–ª—å—à–µ —Å—Ç–∞—Ç–µ–π
        'learning',
        'model',
        'neural'
    ]
    
    def modify_paper(paper):
        """–ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç URL'—ã –¥–ª—è —Å—Ç–∞—Ç—å–∏"""
        paper.forum = f"https://openreview.net/forum?id={paper.forum}"
        if 'pdf' in paper.content:
            paper.content['pdf'] = f"https://openreview.net{paper.content['pdf']}"
        return paper
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ä–µ–≤—å—é
    print("üîß –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ä–µ–≤—å—é...")
    extractor = Extractor(
        fields=['forum'], 
        subfields={'content': ['title', 'keywords', 'abstract', 'pdf', 'match']}, 
        extract_reviews=True  # ‚ú® –ö–õ–Æ–ß–ï–í–ê–Ø –û–ü–¶–ò–Ø!
    )
    
    # –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∞–ø–µ—Ä
    selector = Selector()
    scraper = Scraper(
        conferences=conferences, 
        years=years, 
        keywords=keywords,
        extractor=extractor, 
        fpath='papers_with_reviews_final.csv', 
        fns=[modify_paper], 
        selector=selector
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
    print("üîç –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã...")
    scraper.add_filter(title_filter)
    scraper.add_filter(keywords_filter) 
    scraper.add_filter(abstract_filter)
    scraper.add_filter(reviews_filter)  # ‚ú® –§–∏–ª—å—Ç—Ä –ø–æ —Ä–µ–≤—å—é!
    
    print(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    print(f"   –ö–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏: {conferences}")
    print(f"   –ì–æ–¥—ã: {years}")
    print(f"   –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords}")
    print(f"   –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–≤—å—é: ‚úÖ –í–∫–ª—é—á–µ–Ω–æ")
    print(f"   –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: papers_with_reviews_final.csv")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∞–ø–∏–Ω–≥
    print("\nüï∑Ô∏è –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∞–ø–∏–Ω–≥...")
    scraper()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ...")
    save_papers(scraper.papers, fpath='papers_with_reviews_final.pkl')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("\nüìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç...")
    import os
    import pandas as pd
    
    if os.path.exists('papers_with_reviews_final.csv'):
        df = pd.read_csv('papers_with_reviews_final.csv')
        print(f"‚úÖ CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"   üìÑ –°—Ç–∞—Ç–µ–π: {len(df)}")
        print(f"   üìù –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫ —Å —Ä–µ–≤—å—é
        review_columns = [col for col in df.columns if 'review' in col.lower()]
        if review_columns:
            print(f"   üîç –ö–æ–ª–æ–Ω–∫–∏ —Å —Ä–µ–≤—å—é: {len(review_columns)}")
            for col in review_columns:
                print(f"      - {col}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–µ–≤—å—é
            if 'reviews_count' in df.columns:
                total_reviews = df['reviews_count'].sum()
                avg_reviews = df['reviews_count'].mean()
                print(f"   üìà –í—Å–µ–≥–æ —Ä–µ–≤—å—é: {total_reviews}")
                print(f"   üìà –°—Ä–µ–¥–Ω–µ–µ —Ä–µ–≤—å—é –Ω–∞ —Å—Ç–∞—Ç—å—é: {avg_reviews:.1f}")
            
            if 'reviews_average_rating' in df.columns:
                ratings = df['reviews_average_rating'].dropna()
                if len(ratings) > 0:
                    overall_avg = ratings.mean()
                    print(f"   ‚≠ê –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {overall_avg:.2f}")
        else:
            print("   ‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∏ —Å —Ä–µ–≤—å—é –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        print(f"\nüìã –ü–µ—Ä–≤—ã–µ 5 –∫–æ–ª–æ–Ω–æ–∫:")
        for i, col in enumerate(df.columns[:5], 1):
            print(f"   {i}. {col}")
        
        if len(df.columns) > 5:
            print(f"   ... –∏ –µ—â—ë {len(df.columns) - 5} –∫–æ–ª–æ–Ω–æ–∫")
            
    else:
        print("‚ùå CSV —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω - –≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π, –ø—Ä–æ—à–µ–¥—à–∏—Ö —Ñ–∏–ª—å—Ç—Ä—ã")
        print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–ª–∏ —É–±—Ä–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã")

    print("\nüéâ –ì–æ—Ç–æ–≤–æ!")
    print("üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
    print("   - papers_with_reviews_final.csv (—Ç–∞–±–ª–∏—Ü–∞)")
    print("   - papers_with_reviews_final.pkl (–±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)")

if __name__ == "__main__":
    main() 